{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2: Линейные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <hr\\>\n",
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 24 марта 18:00 Сдача **очная** на занятии. <br\\>\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. В противном случае -1 балл\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здравствуйте, уважаемые студенты! \n",
    "\n",
    "В этом задании мы будем реализовать линейные модели. Необходимо реализовать линейную и логистическую регрессии с L2 регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретическое введение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия решает задачу регрессии и оптимизирует функцию потерь MSE \n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right], $$ где $y_i$ $-$ целевая функция,  $a_i = a(x_i) =  \\langle\\,x_i,w\\rangle ,$ $-$ предсказание алгоритма на объекте $x_i$, $w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Не забываем, что здесь и далее  мы считаем, что в $x_i$ есть тождественный вектор единиц, ему соответствует вес $w_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия является линейным классификатором, который оптимизирует так называемый функционал log loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right],$$\n",
    "где  $y_i  \\in \\{0,1\\}$ $-$ метка класса, $a_i$ $-$ предсказание алгоритма на объекте $x_i$. Модель пытается предсказать апостериорую вероятность объекта принадлежать к классу \"1\":\n",
    "$$ p(y_i = 1 | x_i) = a(x_i) =  \\sigma( \\langle\\,x_i,w\\rangle ),$$\n",
    "$w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Функция $\\sigma(x)$ $-$ нелинейная функция, пероводящее скалярное произведение объекта на веса в число $\\in (0,1)$ (мы же моделируем вероятность все-таки!)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "Если внимательно посмотреть на функцию потерь, то можно заметить, что в зависимости от правильного ответа алгоритм штрафуется или функцией $-\\log a_i$, или функцией $-\\log (1 - a_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто для решения проблем, которые так или иначе связаны с проблемой переобучения, в функционал качества добавляют слагаемое, которое называют ***регуляризацией***. Итоговый функционал для линейной регрессии тогда принимает вид:\n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right] + \\frac{1}{C}R(w) $$\n",
    "\n",
    "Для логистической: \n",
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right] +  \\frac{1}{C}R(w)$$\n",
    "\n",
    "Самое понятие регуляризации введено основателем ВМК академиком Тихоновым https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова\n",
    "\n",
    "Идейно методика регуляризации заключается в следующем $-$ мы рассматриваем некорректно поставленную задачу (что это такое можно найти в интернете), для того чтобы сузить набор различных вариантов (лучшие из которых будут являться переобучением ) мы вводим дополнительные ограничения на множество искомых решений. На лекции Вы уже рассмотрели два варианта регуляризации.\n",
    "\n",
    "$L1$ регуляризация:\n",
    "$$R(w) = \\sum_{j=1}^{D}|w_j|$$\n",
    "$L2$ регуляризация:\n",
    "$$R(w) =  \\sum_{j=1}^{D}w_j^2$$\n",
    "\n",
    "С их помощью мы ограничиваем модель в  возможности выбора каких угодно весов минимизирующих наш лосс, модель уже не сможет подстроиться под данные как ей угодно. \n",
    "\n",
    "Вам нужно добавить соотвествущую Вашему варианту $L2$ регуляризацию.\n",
    "\n",
    "И так, мы поняли, какую функцию ошибки будем минимизировать, разобрались, как получить предсказания по объекту и обученным весам. Осталось разобраться, как получить оптимальные веса. Для этого нужно выбрать какой-то метод оптимизации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск является самым популярным алгоритмом обучения линейных моделей. В этом задании Вам предложат реализовать стохастический градиентный спуск или  мини-батч градиентный спуск (мини-батч на русский язык довольно сложно перевести, многие переводят это как \"пакетный\", но мне не кажется этот перевод удачным). Далее нам потребуется определение **эпохи**.\n",
    "Эпохой в SGD и MB-GD называется один проход по **всем** объектам в обучающей выборки.\n",
    "* В SGD градиент расчитывается по одному случайному объекту. Сам алгоритм выглядит примерно так:\n",
    "        1) Перемешать выборку\n",
    "        2) Посчитать градиент функции потерь на одном объекте (далее один объект тоже будем называть батчем)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* В Mini Batch SGD - по подвыборке объектов. Сам алгоритм выглядит примерно так::\n",
    "        1) Перемешать выборку, выбрать размер мини-батча (от 1 до размера выборки)\n",
    "        2) Почитать градиент функции потерь по мини-батчу (не забыть поделить на  число объектов в мини-батче)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* Для отладки алгоритма реализуйте возможность  вывода средней ошибки на обучении модели по объектам (мини-батчам). После шага градиентного спуска посчитайте значение ошибки на объекте (или мини-батче), а затем усредните, например, по ста шагам. Если обучение проходит корректно, то мы должны увидеть, что каждые 100 шагов функция потерь уменьшается. \n",
    "* Правило останова - максимальное количество эпох\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы (2 балла)\n",
    "В этой части Вам будут предложены теоретичские вопросы и задачи по теме. Вы, конечно, можете списать их у своего товарища или найти решение в интернете, но учтите, что они обязательно войдут в теоретический коллоквиум. Лучше разобраться в теме сейчас и успешно ответить на коллоквиуме, чем списать, не разобравшись в материале, и быть терзаемым совестью. \n",
    "\n",
    "\n",
    "Формулы надо оформлять в формате **LaTeX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1. Градиент для линейной регрессии.\n",
    "* Выпишите формулу обновления весов для линейной регрессии с L2 регуляризацией для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***\n",
    "$$ w_i^k = w_{i-1}^k-\\alpha\\left[\\frac{2}{N}\\sum \\limits_{i}^{n} x_{i}^k(a_i-y_i) + \\frac{2}{C}w^k_{i-1}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 2. Градиент для логистической регрессии.\n",
    "* Выпишите формулу обновления весов для логистической регрессии с L2 регуляризацией  для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент? Как соотносится этот градиент с градиентом, возникающий в задаче линейной регрессии?\n",
    "\n",
    "Подсказка: Вам градиент, которой получается если “в лоб” продифференцировать,  надо немного преобразовать.\n",
    "Надо подставить, что $1 - \\sigma(w,x) $ это  $1 - a(x_i)$, а  $-\\sigma(w,x)$ это $0 - a(x_i)$.  Тогда получится свести к одной красивой формуле с линейной регрессией, которую программировать будет намного проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***\n",
    "$$ w_i^k = w_{i-1}^k-\\alpha\\left[\\frac{1}{N}\\sum \\limits_{i}^{n} x_{i}^k(a_i-y_i) + \\frac{2}{C}w^k_{i-1}\\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 3. Точное решение линейной регрессии\n",
    "\n",
    "На лекции было показано, что точное решение линейной регрессии имеет вид $w = (X^TX)^{-1}X^TY $. \n",
    "* Покажите, что это действительно является точкой минимума в случае, если матрица X имеет строк не меньше, чем столбцов и имеет полный ранг. Подсказка: посчитайте Гессиан и покажите, что в этом случае он положительно определен. \n",
    "* Выпишите точное решение для модели с $L2$ регуляризацией. Как L2 регуляризация помогает с точным решением где матрица X имеет линейно зависимые признаки?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***\n",
    "Для модели с L2 регуляризацией: $w = (X^TX + \\alpha E)^{-1}X^TY $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 4.  Предсказываем вероятности.\n",
    "\n",
    "Когда говорят о логистической регрессии, произносят фразу, что она \"предсказывает вероятности положительного класса\". Давайте разберемся, что же за этим стоит. Посчитаем математическое ожидание функции потерь и проверим, что предсказание алгоритма, оптимизирующее это мат. ожидание, будет являться вероятностью положительного класса. \n",
    "\n",
    "И так, функция потерь на объекте $x_i$, который имеет метку $y_i \\in \\{0,1\\}$  для предсказания $a(x_i)$ равна:\n",
    "$$L(y_i, b) =-[y_i == 1] \\log a(x_i)  - [y_i == 0] \\log(1 - a(x_i)) $$\n",
    "\n",
    "Где $[]$ означает индикатор $-$ он равен единице, если значение внутри него истинно, иначе он равен нулю. Тогда мат. ожидание при условии конкретного $x_i$  по определение мат. ожидания дискретной случайной величины:\n",
    "$$E(L | x_i) = -p(y_i = 1 |x_i ) \\log a(x_i)  - p(y_i = 0 | x_i) \\log( 1 - a(x_i))$$\n",
    "* Докажите, что значение $a(x_i)$, минимизирующее данное мат. ожидание, в точности равно $p(y_i = 1 |x_i)$, то есть равно вероятности положительного класса.\n",
    "\n",
    "Подсказка: возможно, придется воспользоваться, что  $p(y_i = 1 | x_i) + p(y_i = 0 | x_i) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 5.  Смысл регуляризации.\n",
    "\n",
    "Нужно ли в L1/L2 регуляризации использовать свободный член $w_0$ (который не умножается ни на какой признак)?\n",
    "\n",
    "Подсказка: подумайте, для чего мы вводим $w_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***\n",
    "Нет,не нужно,так как w0 мы в вводим для начального отступа по оси одного из признаков,а регуляризацию мы проводим,чтобы наша модель не переобучилась и в тоже время не была не дообучена,то есть мы изменяем \"изгиб графика\",а w0 к нему не имеет никакого отношения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Реализация линейной модели (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зачем нужны батчи?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как Вы могли заметить из теоретического введения, что в случае SGD, что в случа mini-batch GD,  на каждой итерации обновление весов  происходит только по небольшой части данных (1 пример в случае SGD, batch примеров в случае mini-batch). То есть для каждой итерации нам *** не нужна вся выборка***. Мы можем просто итерироваться по выборке, беря батч нужного размера (далее 1 объект тоже будем называть батчом).\n",
    "\n",
    "Легко заметить, что в этом случае нам не нужно загружать все данные в оперативную память, достаточно просто считать батч с диска, обновить веса, считать диска другой батч и так далее. В целях упрощения домашней работы, прямо с диска  мы считывать не будем, будем работать с обычными numpy array. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немножко про генераторы в Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея считывания данных кусками удачно ложится на так называемые ***генераторы*** из языка Python. В данной работе Вам предлагается не только разобраться с логистической регрессией, но  и познакомиться с таким важным элементом языка.  При желании Вы можете убрать весь код, связанный с генераторами, и реализовать логистическую регрессию и без них, ***штрафоваться это никак не будет***. Главное, чтобы сама модель была реализована правильно, и все пункты были выполнены. \n",
    "\n",
    "Подробнее можно почитать вот тут https://anandology.com/python-practice-book/iterators.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К генератору стоит относиться просто как к функции, которая порождает не один объект, а целую последовательность объектов. Новое значение из последовательности генерируется с помощью ключевого слова ***yield***. Ниже Вы можете насладиться  генератором чисел Фибоначчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(max_iter=4):\n",
    "    a, b = 0, 1\n",
    "    iter_num = 0\n",
    "    while 1:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        iter_num += 1\n",
    "        if iter_num == max_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так можно сгенерировать последовательность Фибоначчи. \n",
    "\n",
    "Заметьте, что к генераторам можно применять некоторые стандартные функции из Python, например enumerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for j, fib_val in enumerate(new_generator):\n",
    "    print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересоздавая объект, можно сколько угодно раз генерировать заново последовательность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    new_generator = fib()\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так уже нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for i in range(0, 3):\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Концепция крайне удобная для обучения  моделей $-$ у Вас есть некий источник данных, который Вам выдает их кусками, и Вам совершенно все равно откуда он их берет. Под ним может скрывать как массив в оперативной памяти, как файл на жестком диске, так и SQL база данных. Вы сами данные никуда не сохраняете, оперативную память экономите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Вам понравилась идея с генераторами, то Вы можете реализовать свой, используя прототип batch_generator. В нем Вам нужно выдавать батчи признаков и ответов для каждой новой итерации спуска. Если не понравилась идея, то можете реализовывать SGD или mini-batch GD без генераторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, shuffle=True, batch_size=1):\n",
    "    \"\"\"\n",
    "    Гератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        vb = np.random.permutation(X.shape[0])\n",
    "    else:\n",
    "        vb = np.array(X.shape[0])\n",
    "    vb = vb.reshape(X.shape[0] // batch_size, batch_size)\n",
    "    for i in range(0, vb.shape[0]):\n",
    "        X_batch = X[vb[i]]\n",
    "        y_batch = y[vb[i]]\n",
    "        yield (X_batch, y_batch)\n",
    "\n",
    "# Теперь можно сделать генератор по данным ()\n",
    "#  my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1):\n",
    "#ОК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - выход линейной модели\n",
    "    \"\"\"\n",
    "    sigm_value_x = 1 / (1+ np.exp(-x))\n",
    "    return sigm_value_x #ОК Your code Here\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, batch_generator, C=1, alpha=0.01, max_epoch=10, model_type='lin_reg', batch_size = 1):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        model_type - тим модели, lin_reg или log_reg\n",
    "        \"\"\"\n",
    "        \n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter' : [], 'loss' : []}  \n",
    "        self.model_type = model_type\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def calc_loss(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        if self.model_type == 'lin_reg':\n",
    "            loss = self.predict(X_batch) - y_batch\n",
    "            loss = np.multiply(loss.T, loss)\n",
    "            loss = np.mean(loss, axis=0)\n",
    "            loss += np.dot(self.weights.T, self.weights)[0] *self.C\n",
    "        if self.model_type == 'log_reg' :\n",
    "            prediction = self.predict(X_batch)\n",
    "            loss = -(y_batch.reshape(-1, 1) * np.log(prediction) +\n",
    "            (1 - y_batch.reshape(-1, 1)) * np.log(1 - prediction))\n",
    "            loss = np.mean(loss, axis=0)\n",
    "            loss += np.dot(self.weights.T, self.weights)[0] * self.C\n",
    "        return loss[0]\n",
    "    \n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем  градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        if self.model_type == 'lin_reg':\n",
    "            prediction = self.predict(X_batch)\n",
    "            vb = X_batch * (prediction - y_batch)\n",
    "            loss_grad = 2 * np.mean(vb, axis=0) + 2 * self.weights.T * self.C\n",
    "        if self.model_type == 'log_reg':\n",
    "            prediction = self.predict(X_batch)\n",
    "            vb = X_batch * (prediction - y_batch.reshape(-1, 1))\n",
    "            loss_grad = np.mean(vb, axis=0) + 2 * self.weights.T * self.C\n",
    "        return loss_grad.reshape(-1,1)\n",
    "    \n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights -= self.alpha*new_grad\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        '''\n",
    "        X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "        X = np.concatenate((X, np.ones(X.shape[0]).reshape(-1, 1)), axis=1)\n",
    "        self.weights = np.random.rand(X.shape[1])\n",
    "        self.weights = self.weights.reshape(-1, 1)\n",
    "        for n in range(0, self.max_epoch):\n",
    "            new_epoch_generator = self.batch_generator(X, y, self.batch_size)\n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                self.update_weights(batch_grad)\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        '''\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        '''\n",
    "        if self.model_type == 'lin_reg':\n",
    "            return X.dot(self.weights)\n",
    "        if self.model_type== 'log reg':\n",
    "            return (sigmoid(X.dot(self.weighte)))\n",
    "        \n",
    "        \n",
    "       \n",
    "        # Желательно здесь использовать матричные операции между X и весами, например, numpy.dot \n",
    "        #return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите обе регрессии на синтетических данных. \n",
    "\n",
    "\n",
    "Выведите полученные веса и нарисуйте разделяющую границу между классами (используйте только первых два веса для первых двух признаков X[:,0], X[:,1] для отображения в 2d пространство ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf):\n",
    "    a = clf.weights.flatten()\n",
    "    x = np.linspace(-4, 4)\n",
    "    y = (-a[1]/a[0]) * x\n",
    "    plt.plot(x, y, label='model = {}'.format(clf.model_type))\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "   ## Your code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-faa3988a4767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_reg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-dd3be68f75a3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[0mbatch_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_loss_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-dd3be68f75a3>\u001b[0m in \u001b[0;36mcalc_loss\u001b[1;34m(self, X_batch, y_batch)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'log_reg'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             loss = -(y_batch.reshape(-1, 1) * np.log(prediction) +\n\u001b[0m\u001b[0;32m     48\u001b[0m             (1 - y_batch.reshape(-1, 1)) * np.log(1 - prediction))\n\u001b[0;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'log'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "C1 = np.array([[0., -0.8], [1.5, 0.8]])\n",
    "C2 = np.array([[1., -0.7], [2., 0.7]])\n",
    "gauss1 = np.dot(np.random.randn(200, 2) + np.array([5, 3]), C1)\n",
    "gauss2 = np.dot(np.random.randn(200, 2) + np.array([1.5, 0]), C2)\n",
    "\n",
    "X = np.vstack([gauss1, gauss2])\n",
    "y = np.r_[np.ones(200), np.zeros(200)]\n",
    "\n",
    "model = MySGDClassifier(batch_generator, model_type='lin_reg')\n",
    "model.fit(X, y)\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "model = MySGDClassifier(batch_generator, model_type='log_reg')\n",
    "model.fit(X, y)\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "\n",
    "X=X - np.mean(X, axis = 0)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "# plot_decision_boundary(your_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем анализировать Ваш алгоритм. \n",
    "Для этих заданий используйте датасет ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_features=10, \n",
    "                           n_informative=4, n_redundant=0, \n",
    "                           random_state=123, class_sep=1.0,\n",
    "                           n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите сходимости обеих регрессией на этом датасете: изобразите график  функции потерь, усредненной по $N$ шагам градиентого спуска, для разных `alpha` (размеров шага). Разные `alpha` расположите на одном графике. \n",
    "\n",
    "$N$ можно брать 10, 50, 100 и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MySGDClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d245e95436c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmyclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_reg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmyclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MySGDClassifier' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "alphas = (0.01, 0.05, 0.1)\n",
    "N = 100\n",
    "\n",
    "for alpha in alphas:\n",
    "    myclf = MySGDClassifier(batch_generator, alpha=alpha, model_type='log_reg')\n",
    "    myclf.fit(X, y)\n",
    "    steps = len(myclf.errors_log['loss'])\n",
    "    mean_losses = []\n",
    "    for i in range(steps // N):\n",
    "        s = np.sum(myclf.errors_log['loss'][i*N:(i+1)*N]) / N\n",
    "        mean_losses.append(s)\n",
    "        \n",
    "    model_type = 'log_reg'\n",
    "    plt.plot(np.arange(len(mean_losses)), mean_losses, label='alpha = {} model = {}'.format(alpha, model_type))\n",
    "    \n",
    "    myclf = MySGDClassifier(batch_generator, alpha=alpha, model_type='lin_reg')\n",
    "    myclf.fit(X, y)\n",
    "    steps = len(myclf.errors_log['loss'])\n",
    "    mean_losses = []\n",
    "    for i in range(steps // N):\n",
    "        s = np.sum(myclf.errors_log['loss'][i*N:(i+1)*N]) / N\n",
    "        mean_losses.append(s)\n",
    "        \n",
    "    model_type = 'lin_reg'\n",
    "    plt.plot(np.arange(len(mean_losses)), mean_losses, label='alpha = {} model = {}'.format(alpha, model_type))\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что Вы можете сказать про сходимость метода при различных `alpha`? Какое значение стоит выбирать для лучшей сходимости?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите график среднего значения весов для обеих регрессий в зависимости от коеф. регуляризации С из `np.logspace(3, -3, 10)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MySGDClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2408383dae6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_reg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mwghts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MySGDClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "wghts = []\n",
    "C = np.logspace(3, -3, 10)\n",
    "for c in C:\n",
    "    clf = MySGDClassifier(batch_generator, C=c, max_epoch=1,model_type='log_reg')\n",
    "    clf.fit(X, y)\n",
    "    wghts.append(np.mean(np.abs(clf.weights)))\n",
    "plt.plot(wghts)## Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MySGDClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-10f032dad343>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lin_reg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mwghts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MySGDClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "wghts = []\n",
    "C = np.logspace(3, -3, 10)\n",
    "for c in C:\n",
    "    clf = MySGDClassifier(batch_generator, C=c, max_epoch=1,model_type='lin_reg')\n",
    "    clf.fit(X, y)\n",
    "    wghts.append(np.mean(np.abs(clf.weights)))\n",
    "plt.plot(wghts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольны ли Вы, насколько сильно уменьшились Ваши веса?\n",
    "ахахаа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Боевое применение (4  балла)\n",
    "\n",
    "**Защита данной части возможна только при преодолении в проекте бейзлайна Handmade baseline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте применим модель на итоговом проекте! Датасет сделаем точно таким же образом, как было показано в project_overview.ipynb\n",
    "\n",
    "Применим обе регрессии, подберем для них параметры и сравним качество. Может быть Вы еще одновременно с решением домашней работы подрастете на лидерборде!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'docs_titles.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f82a2311f769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdoc_to_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'docs_titles.tsv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_line\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'docs_titles.tsv'"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'train_groups.csv' does not exist: b'train_groups.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-43775d034882>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_groups.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtraingroups_titledata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnew_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train_groups.csv' does not exist: b'train_groups.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traingroups_titledata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2c0bc1a51d1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgroups_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mnew_group\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraingroups_titledata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraingroups_titledata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_group\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'traingroups_titledata' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        X_train.append(sorted(all_dist, reverse=True)[0:15]    )\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите размер батча для обучения. Линейная модель не должна учиться дольше нескольких минут. \n",
    "\n",
    "Не забывайте использовать скейлер!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте данные на обучение и валидацию. Подберите параметры C, alpha, max_epoch, model_type на валидации (Вы же помните, как правильно в этой задаче делать валидацию?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Подберите порог линейной модели, по достижении которого, Вы будете относить объект к классу 1. Вспомните, какую метрику мы оптимизируем в соревновании.  Как тогда правильно подобрать порог?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С лучшими параметрами на валидации сделайте предсказание на тестовом множестве, отправьте его на проверку на платформу kaggle. Убедитесь, что Вы смогли побить public score первого бейзлайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** При сдаче домашки Вам необходимо кроме ссылки на ноутбук показать Ваш ник на kaggle, под которым Вы залили решение, которое побило Handmade baseline. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения линейных моделей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ВАШ ОТЗЫВ ЗДЕСЬ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
